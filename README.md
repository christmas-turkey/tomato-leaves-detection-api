
# Tomato Leaves Diseases Detection API

This project implements a YOLO model trained on [Kaggle Tomato Leaves Diseases dataset](https://www.kaggle.com/datasets/kpoviesistphane/tomato-leaf-disease-detection) to detect leaf diseases of tomato plants. Also, the API uses an LLM to generate description of detected diseases.

## Installation

First, create a `.env` file in the root directory and set your Fireworks API key

```text
FIREWORKS_API_KEY=<YOUR FIREWORKS API KEY>
```

### Without Docker
1. python 3.11 is required
2. Install Python dependencies `pip install -r requirements.txt`
3. Download YOLO weights `RUN gdown --fuzzy https://drive.google.com/file/d/1cOClJvYkBxURCa3o4FB83fY-QjknNZAR/view?usp=drive_link`. Or, you can train a model on your own using `train_yolo.ipynb` notebook located in the root directory. **Note: the YOLO weights must be located in the root directory and named `yolo_weights.pt`**
4. Run `python -m src.server`

### Docker
1. Run `docker build -t tomato-leaves-api .`
2. Run `docker run -p 5000:5000 tomato-leaves-api`

## API Reference

If running the API locally, it can be accessed on http://127.0.0.1:5000

### Healthcheck

Check if the API is running.

```text
GET /health
```

**Returns:**
  - A message that API is running

### Generate predictions

Predict classes, bboxes and confidence scores of the input image and return LLM response.

```text
POST /api/predict
```

| Parameter | Type     | Description                       |
| :-------- | :------- | :-------------------------------- |
| `image`      | `image/*` | **Required**. An image to generate predictions for |
| `model_name`      | `string` | **Optional**. The name of an LLM to be used. (Defaults to `llama-v3p1-405b-instruct`) |

The following LLMs are supported:
- `llama-v3p1-405b-instruct`
- `llama-v3p1-70b-instruct`
- `llama-v3p1-8b-instruct`
- `llama-v3-70b-instruct`
- `mixtral-8x22b-instruct`
- `mixtral-8x7b-instruct`

**Returns:**
  - **classes**: The classes of the detected objects.
  - **boxes**: The bounding boxes of the detected objects.
  - **conf**: The confidence scores of the detected objects.
  - **labels**: The labels of the detected objects.
  - **llm_response**: The response generated by the LLM.
